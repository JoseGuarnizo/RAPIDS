{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificar versión de gpu Nvidia\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf, cuml, cuxfilter\n",
    "from pandas.io.json import json_normalize \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "#Fase de extracción y lectura con Rapids\n",
    "\n",
    "#extracción y lectura con Pandas\n",
    "pd_Pandas = pd.read_csv('df_data.csv',\n",
    "                        names='uno')\n",
    "\n",
    "#extraccion y lectura con Rapids\n",
    "start = time.time()\n",
    "\n",
    "gdf = cudf.read_csv('df_data.csv',\n",
    "                    names='uno')\n",
    "\n",
    "end = time.time()\n",
    "caculatedCUDF = end - start\n",
    "\n",
    "print(\"Cálculo de extracción y lectura con cudf gpu-Rapdis= {}\".format(caculatedCUDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######Transformación con cudf##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "cudf_Pandas = pd_Pandas\n",
    "\n",
    "#crear formato json para despues crear un dataframe nuevo\n",
    "start = time.time()\n",
    "lista = list(cudf_Pandas['u'])\n",
    "\n",
    "a = []\n",
    "for i in range(0,len(lista)):\n",
    "    d = lista[i].split('.gz:')\n",
    "    a.append(json.loads((d[1])))\n",
    "    \n",
    "#Creo DataFrame con Pandas\n",
    "pdPandas = pd.DataFrame(a)\n",
    "\n",
    "# Convierto todo el dataframe a str\n",
    "nuevo_pdPandas = pdPandas.applymap(str)\n",
    "\n",
    "#Se crear un dataframe con cudf(propia de Rapids)\n",
    "#gdf = cudf.DataFrame.from_pandas(nuevo_pdPandas)\n",
    "\n",
    "#conviero para pandas dataframe(propia de Rapids)\n",
    "#gdfPD = gdf.to_pandas()\n",
    "\n",
    "#solo conservo los datos de la columna username\n",
    "#mayor a 0\n",
    "snNull = nuevo_pdPandas[nuevo_pdPandas.username.map(len) > 0]\n",
    "\n",
    "#elimino username dicc y opencampus\n",
    "snDicc = snNull[snNull.username != 'dicc']\n",
    "snCampus = snDicc[snDicc.username != 'opencampus']\n",
    "\n",
    "#convieto para cudf dataframe\n",
    "gdf_new = cudf.DataFrame.from_pandas(snCampus)\n",
    "\n",
    "#Eliminar columnas que no tiene mucha relevancia\n",
    "gdf_new.drop_column('accept_language') #columna sin relevancia\n",
    "gdf_new.drop_column('name') #muchos datos faltantes\n",
    "gdf_new.drop_column('agent') #columna sin relevancia\n",
    "gdf_new.drop_column('page') #muchos datos faltantes\n",
    "gdf_new.drop_column('session') #muchos datos faltantes\n",
    "gdf_new.drop_column('event') #datos dañados\n",
    "gdf_new.drop_column('event_type') #columna sin relevancia\n",
    "\n",
    "#eliminar filas con los datos perdidos\n",
    "gdf_new.dropna(axis=0, how='any')\n",
    "\n",
    "#Dividir columna context estaba en json\n",
    "newContext = gdf_new['context'].tolist()\n",
    "b=[]\n",
    "for i in range(0,len(newContext)):\n",
    "    d = newContext[i].split(',')\n",
    "    b.append(d[1])\n",
    "\n",
    "gdfContext = cudf.DataFrame()\n",
    "gdfContext['General'] = b\n",
    "gdfContext = gdfContext['General'].str.split()\n",
    "gdfContext.drop_column(0)\n",
    "gdfContext.columns=['userid_orgid']\n",
    "\n",
    "#Unir\n",
    "newData = gdf_new.join(gdfContext, how='left')\n",
    "newData.drop_column('context')\n",
    "\n",
    "#eliminar filas con datos perdidos\n",
    "newData.dropna(axis=0, how='any')\n",
    "\n",
    "#soltar duplicados\n",
    "newData.sort_values('username') \n",
    "newData.drop_duplicates(subset='username', keep=False, inplace=False, ignore_index=False)\n",
    "\n",
    "\n",
    "#dividir columna time\n",
    "vtime = newData['time']\n",
    "#vtime.str.normalize_spaces()\n",
    "new_time = vtime.str.split(pat = \"-\")\n",
    "\n",
    "day = new_time[2]\n",
    "daytime = day.str.split(pat = 'T')\n",
    "daytime.drop_column(1)\n",
    "daytime.columns = ['day']\n",
    "\n",
    "timenew = new_time.join(daytime, how='left')\n",
    "timenew.drop_column(2)\n",
    "timenew.columns = ['year','month','day']\n",
    "\n",
    "#Unir todo al dataframe time al general\n",
    "newData = newData.join(timenew)\n",
    "newData.drop_column('time')\n",
    "\n",
    "#eliminar filas con datos perdidos\n",
    "newData.dropna(axis=0, how='any')\n",
    "\n",
    "#resetear index\n",
    "newData = newData.reset_index()\n",
    "newData.drop_column('index')\n",
    "\n",
    "end = time.time()\n",
    "calculo_Transform= end - start\n",
    "\n",
    "print('Cálculo de transformación con cudf gpu-Rapdis:', calculo_Transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploración de todo el Dataset con RAPIDS\n",
    "print('Nombre de columnas:',newData.columns)\n",
    "print('Dimension DataFrame:',newData.shape)\n",
    "print('Tipos de datos de cada columna', newData.dtypes)\n",
    "print('Información DATA general con Rapids:')\n",
    "newData.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########Carga con Rapids#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar la data entendible en un nuevo csv\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "da_data = 'data_mejora.csv'\n",
    "newData.to_csv(da_data)\n",
    "\n",
    "end = time.time()\n",
    "calculated = end - start\n",
    "\n",
    "print(\"Cálculo carga con cudf gpu-Rapdis = {}\".format(calculated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nueva_data = cudf.read_csv('data_mejora.csv')\n",
    "nueva_data.drop_column('Unnamed: 0')\n",
    "\n",
    "print('Tipos de datos de cada columna', newData.dtypes)\n",
    "print('Información Data')\n",
    "nueva_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Proceso Machine Learning##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "\n",
    "#Asignar dataset general a nuevas variables\n",
    "gdf_dataX = nueva_data\n",
    "gdf_dataY = nueva_data\n",
    "\n",
    "#Dividir datasets en train y test\n",
    "#datatrain 80% y datatest 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(gdf_dataX, gdf_dataY, train_size=0.8)\n",
    "\n",
    "#información\n",
    "print(f'Dataset Original: {gdf_dataX.shape[0], gdf_dataY.shape[0]} elementos')\n",
    "print(f'Data X_train: {X_train.shape[0]} elements')\n",
    "print(f'Data X_test: {X_test.shape[0]} elements')\n",
    "print(f'Data y_train: {y_train.shape[0]} elements')\n",
    "print(f'Data y_test: {y_test.shape[0]} elements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from cuml.preprocessing.LabelEncoder import LabelEncoder\n",
    "\n",
    "inicio_Pre = time.time()\n",
    "#Fase2 Preprocesamiento con cuml\n",
    "#Convertir a variables categóricas\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "#seleccionar columnas potenciales para work train de xTrain\n",
    "value_usernameX = le.fit_transform(X_train.username)\n",
    "value_EventSourceX = le.fit_transform(X_train.event_source)\n",
    "value_DayX = le.fit_transform(X_train.day)\n",
    "\n",
    "#seleccionar columnas potenciales para work train de xTest\n",
    "value_usernameXT = le.fit_transform(X_test.username)\n",
    "value_EventSourceXT = le.fit_transform(X_test.event_source)\n",
    "value_DayXT = le.fit_transform(X_test.day)\n",
    "\n",
    "#seleccionar columnas potenciales para work train de yTrain\n",
    "value_usernameY = le.fit_transform(y_train.username)\n",
    "value_EventSourceY = le.fit_transform(y_train.event_source)\n",
    "value_DayY = le.fit_transform(y_train.day)\n",
    "\n",
    "#seleccionar dos columnas potenciales para work train de yTest\n",
    "value_usernameYT = le.fit_transform(y_test.username)\n",
    "value_EventSourceYT = le.fit_transform(y_test.event_source)\n",
    "value_DayYT = le.fit_transform(y_test.day)\n",
    "\n",
    "fin_Pre = time.time()\n",
    "calculo_Pre_ML = fin_Pre - inicio_Pre\n",
    "\n",
    "print(\"Cálculo del proceso Machine Learning con cuml gpu-Rapdis = {}\".format(calculo_Pre_ML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cupy as cp\n",
    "from cuml.linear_model import LinearRegression\n",
    "\n",
    "inicio_ML = time.time()\n",
    "#Fase3 Uso de los algoritmos ML de cuml\n",
    "#Algoritmo LinearRegression\n",
    "\n",
    "#Creación de un nuevo dataframe Train \n",
    "dataTrain = cudf.DataFrame()\n",
    "dataTrain['username'] = cp.asarray(value_usernameX, dtype=cp.float32)\n",
    "dataTrain['day'] = cp.asarray(value_DayX, dtype=cp.float32)\n",
    "\n",
    "#Creación de un nuevo dataframe Test\n",
    "new_value = cp.asarray(value_usernameY, dtype=cp.float32)\n",
    "dataTest = cudf.Series(new_value)\n",
    "\n",
    "#Usar algoritmo LinearRegresssion de cuml\n",
    "lr = LinearRegression(fit_intercept = True, normalize = False,\n",
    "                      algorithm = \"eig\")\n",
    "reg = lr.fit(dataTrain, dataTest)\n",
    "\n",
    "fin_ML = time.time()\n",
    "calculo_Algorit_ML = fin_ML - inicio_ML\n",
    "\n",
    "print(\"Algoritmo Regresión Lineal\")\n",
    "print(\"Coeficientes:\")\n",
    "print(reg.coef_)\n",
    "print('')\n",
    "print(\"Intercepción:\")\n",
    "print(reg.intercept_)\n",
    "print('')\n",
    "print('Predicción del modelo:')\n",
    "print(lr.predict(dataTrain))\n",
    "print('')\n",
    "\n",
    "print(\"Cálculo del proceso Machine Learning con cuml gpu-Rapdis = {}\".format(calculo_Algorit_ML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algoritmo regresión logistica de cuml\n",
    "import time\n",
    "import cupy as cp\n",
    "from cuml.linear_model import LogisticRegression\n",
    "\n",
    "inicio_RL = time.time()\n",
    "\n",
    "\n",
    "#Creación de un nuevo dataframe Train \n",
    "dataTrain = cudf.DataFrame()\n",
    "dataTrain['username'] = cp.asarray(value_usernameX, dtype=cp.float32)\n",
    "dataTrain['day'] = cp.asarray(value_DayX, dtype=cp.float32)\n",
    "\n",
    "#Creación de un nuevo dataframe Test\n",
    "new_value = cp.asarray(value_usernameY, dtype=cp.float32)\n",
    "dataTest = cudf.Series(new_value)\n",
    "\n",
    "reg_lo = LogisticRegression()\n",
    "reg_lo.fit(dataTrain,dataTest)\n",
    "\n",
    "fin_RL = time.time()\n",
    "calculo_RL = fin_RL - inicio_RL\n",
    "\n",
    "print(\"Coefficients:\")\n",
    "print(reg_lo.coef_.to_output('cupy'))\n",
    "print(\"Intercept:\")\n",
    "print(reg_lo.intercept_.to_output('cupy'))\n",
    "print('Predicción del modelo:')\n",
    "print(reg_lo.predict(dataTrain))\n",
    "print('')\n",
    "\n",
    "print(\"Cálculo del algoritmo Regresión Logistica con cuml gpu-Rapdis = {}\".format(calculo_RL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########Visualización###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuxfilter import DataFrame, themes, layouts\n",
    "from cuxfilter.assets.custom_tiles import get_provider, Vendors\n",
    "\n",
    "inicioV = time.time()\n",
    "cux_df = cuxfilter.DataFrame.from_dataframe(dataTrain)\n",
    "\n",
    "#crear gráfico de barras estadísticas\n",
    "bar_chart_1 = cuxfilter.charts.bar('day', 'username', title='Gráfico de Barras Estadístico', data_points=5, add_interaction=False)\n",
    "d = cux_df.dashboard([bar_chart_1])\n",
    "\n",
    "finV = time.time()\n",
    "calculo_V = finV - inicioV\n",
    "print(\"Cálculo del proceso Visualización gpu-cuxfilter = {}\".format(calculo_V))\n",
    "print('')\n",
    "\n",
    "bar_chart_1.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear gráfico de líneas estadisticas\n",
    "line_chart_1 = cuxfilter.charts.line('day', 'username', title='Gráfico de Lineas Estadístico', data_points=5, add_interaction=False)\n",
    "dl = cux_df.dashboard([line_chart_1])\n",
    "\n",
    "line_chart_1.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráfico general\n",
    "d = cux_df.dashboard([bar_chart_1, line_chart_1], layout=cuxfilter.layouts.triple_feature, theme=cuxfilter.themes.rapids, title=\"Gráficos General Estadísticos\")\n",
    "await d.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Detalles de todo el ambiente datascience####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir columna course_user_tags\n",
    "#newcontext.columns = ['course_user_tags','user_id','org_id']\n",
    "#newcontext.head(2)\n",
    "\n",
    "#dfnewcontext = newcontext[\"course_user_tags\"].str.split(':', expand=True)\n",
    "#dfnewcontext.sort_values(0)\n",
    "#dfnewcontext.drop_duplicates(1, keep=\"last\", inplace=True)\n",
    "#dfnewcontext.drop(0, inplace=True)\n",
    "#dfnewcontext.columns = ['user_id']\n",
    "#indexNames = dfnewcontext[dfnewcontext['user_id'] == '{}' ].index\n",
    "#nuevodf = dfnewcontext.drop(indexNames, inplace=True)\n",
    "#nuevodf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algoritmo Random Forest de cuml\n",
    "#import cupy as cp\n",
    "#from cuml.datasets.classification import make_classification\n",
    "#from cuml.ensemble import RandomForestClassifier as cuRFC\n",
    "\n",
    "#inicioRF = time.time()\n",
    "\n",
    "#dataTrainUSER = cp.asarray(value_usernameX, dtype=cp.float32)\n",
    "#dataTestUSER = cp.asarray(value_usernameY, dtype=cp.int32)\n",
    "\n",
    "\n",
    "#dataTrainUSER, dataTestUSER = make_classification(n_samples=2, n_features=2,\n",
    "#                                                 n_informative=2, n_redundant=0,\n",
    "#                                                 random_state=0)\n",
    "\n",
    "#cuml_model_RDF = cuRFC(max_features=1.0,\n",
    "#                   n_bins=2,\n",
    "#                   n_estimators=2)\n",
    "\n",
    "#cuml_model_RDF.fit(dataTrainUSER, dataTestUSER)\n",
    "#cuml_predict = cuml_model_RDF.predict(dataTrainUSER)\n",
    "\n",
    "#finRF = time.time()\n",
    "#calculoRF = finRF - inicioRF\n",
    "\n",
    "#print('Predict labels:', cuml_predict)\n",
    "#print('')\n",
    "\n",
    "#print(\"Cálculo fase de entrenamiento algoritmo Random Forest con cuml = {}\".format(calculoRF))\n",
    "\n",
    "#Resultado erroneo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
