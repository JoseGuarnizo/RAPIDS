{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_cudf\n",
    "import cudf, cuml, cugraph\n",
    "import json\n",
    "from pandas.io.json import json_normalize \n",
    "import pandas as pd \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fase load PANDAS, RAPIDS and Dask_RAPIDS\n",
    "\n",
    "pd_Pandas = pd.read_csv('../df_data.csv', names='uno')\n",
    "\n",
    "#read with cudf\n",
    "start = time.time()\n",
    "gdf = cudf.read_csv('../df_data.csv', names='uno')\n",
    "end = time.time()\n",
    "\n",
    "caculatedCUDF = end - start\n",
    "print(\"Cálculo de lectura con RAPIDS = {}\".format(caculatedCUDF))\n",
    "\n",
    "#read with dask_cudf\n",
    "daskstart = time.time()\n",
    "dask_gdf = dask_cudf.read_csv('../df_data.csv', names='uno')\n",
    "daskend = time.time()\n",
    "\n",
    "caculatedDASKCUDF = daskend - daskstart\n",
    "print(\"Cálculo de lectura con DASK_CUDF = {}\".format(caculatedDASKCUDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudf_Pandas = pd_Pandas\n",
    "print('Descripción de salida del dataset:')\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fase Transformation\n",
    "#Dataset more understandable\n",
    "\n",
    "import json\n",
    "#create format json for later create dataframe\n",
    "start = time.time()\n",
    "lista = list(cudf_Pandas['u'])\n",
    "a = []\n",
    "\n",
    "for i in range(0,len(lista)):\n",
    "    d = lista[i].split('.gz:')\n",
    "    nuevo = d[1]\n",
    "    a.append(json.loads((nuevo)))\n",
    "    \n",
    "#Create DataFrame with Pandas\n",
    "pdPandas = pd.DataFrame(a)\n",
    "\n",
    "# Convierto todo a str para que la entrega funcione\n",
    "#Pandas a cudf, si no lo convierto me arroja errores y no puedes\n",
    "#convertir en un marco de datos\n",
    "nuevo_pdPandas = pdPandas.applymap(str)\n",
    "\n",
    "#Crear DataFrane con cudf\n",
    "gdf = cudf.DataFrame.from_pandas(nuevo_pdPandas)\n",
    "\n",
    "#convertir para Pandas\n",
    "gdfPD = gdf.to_pandas()\n",
    "\n",
    "# solo conservo el día de la columna 'username'\n",
    "#mayor a 0\n",
    "snNull = gdfPD[gdfPD.username.map(len) > 0]\n",
    "\n",
    "# elimino username dicc y opencampus\n",
    "snDicc = snNull[snNull.username != 'dicc']\n",
    "snCampus = snDicc[snDicc.username != 'opencampus']\n",
    "\n",
    "#convertio para cuDF\n",
    "gdf_new = cudf.DataFrame.from_pandas(snCampus)\n",
    "\n",
    "#eliminar filas con los datos perdidos\n",
    "gdf_new.dropna(axis=0, how='any')\n",
    "\n",
    "#Eliminar columnas que no tiene mucha relevancia\n",
    "gdf_new.drop_column('accept_language') #columna si relevancia\n",
    "gdf_new.drop_column('name') #muchos datos faltantes\n",
    "gdf_new.drop_column('agent') #columna si relevancia\n",
    "gdf_new.drop_column('page') #muchos datos faltantes\n",
    "gdf_new.drop_column('session') #muchos datos faltantes\n",
    "gdf_new.drop_column('event') #datos dañados\n",
    "gdf_new.drop_column('event_type') #columna si relevancia\n",
    "\n",
    "#Valores server = 1, browser = 2\n",
    "gdf_new['event_source'].replace(['server','browser'],\n",
    "                                [1,2],inplace=True)\n",
    "\n",
    "#Valor opencampus.utpl.edu.ec = 1\n",
    "gdf_new['host'].replace(['opencampus.utpl.edu.ec','soer.utpl.edu.ec'],\n",
    "                        [1,2],inplace=True)\n",
    "\n",
    "#ip a formato int\n",
    "gdf_new['ip'] = gdf_new['ip']\n",
    "gdf_new['ip'].str.ip2int()\n",
    "\n",
    "#Dividir columna context estaba en json\n",
    "context = gdf_new['context']\n",
    "context.str.normalize_spaces()\n",
    "newcontext = context.str.split(pat = \",\")\n",
    "newcontext.drop_column(3)\n",
    "newcontext.drop_column(4)\n",
    "newcontext.drop_column(5)\n",
    "newcontext.drop_column(6)\n",
    "\n",
    "#Cambiar nombre a las columnas\n",
    "newcontext.columns = ['a','b','c']\n",
    "\n",
    "#Unir\n",
    "newData = gdf_new.join(newcontext, how='left')\n",
    "newData.drop_column('context')\n",
    "\n",
    "#eliminar filas con datos perdidos\n",
    "newData.dropna(axis=0, how='any')\n",
    "\n",
    "#soltar duplicados\n",
    "newData.sort_values('username') \n",
    "newData.drop_duplicates(subset='username', keep=False, inplace=False, ignore_index=False)\n",
    "\n",
    "#resetear index\n",
    "newData = newData.reset_index()\n",
    "newData.drop_column('index')\n",
    "\n",
    "#eliminar filas con datos perdidos\n",
    "newData.dropna(axis=0, how='any')\n",
    "\n",
    "end = time.time()\n",
    "calculatedGeneralRAPIDS = end - start\n",
    "\n",
    "print('Cálculo de transformación RAPIDS:', calculatedGeneralRAPIDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividir columna time\n",
    "time = newData['time']\n",
    "time.str.normalize_spaces()\n",
    "newtime = time.str.split(pat = \"-\")\n",
    "\n",
    "day = newtime[2]\n",
    "day.str.normalize_spaces()\n",
    "daytime = day.str.split(pat = 'T')\n",
    "daytime.drop_column(1)\n",
    "daytime.columns = ['day']\n",
    "\n",
    "timenew = newtime.join(daytime, how='left')\n",
    "timenew.drop_column(2)\n",
    "timenew.columns = ['year','month','day']\n",
    "\n",
    "#Unir todo al dataframe general\n",
    "newData = newData.join(timenew)\n",
    "newData.drop_column('time')\n",
    "\n",
    "#eliminar filas con datos perdidos\n",
    "newData.dropna(axis=0, how='any')\n",
    "\n",
    "#resetear index\n",
    "newData = newData.reset_index()\n",
    "newData.drop_column('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Informacion de todo el dataset transformado\n",
    "print('Names columns:',newData.columns)\n",
    "print('Dataframe empty yes or no:',newData.empty)\n",
    "print('Dimension DataFrame:',newData.shape)\n",
    "print('Verificar valores nulos por cada columna:',newData.isnull().sum())\n",
    "\n",
    "print('Information DATA general again with RAPIDS:')\n",
    "newData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar la data entendible en un nuevo csv\n",
    "start = time.time()\n",
    "da_data = 'data_mejora.csv'\n",
    "newData.to_csv(da_data)\n",
    "end = time.time()\n",
    "\n",
    "calculated = end - start\n",
    "\n",
    "print(\"Cálculo de lectura con DASK_CUDF = {}\".format(calculated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nueva_data = cudf.read_csv('data_mejora.csv')\n",
    "nueva_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Splitting with cuml\n",
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "\n",
    "#Assign dataset general a new variables\n",
    "gdf_dataX = nueva_data\n",
    "gdf_dataY = nueva_data\n",
    "\n",
    "\n",
    "#Divide datasets in train and test\n",
    "#datatrain 80% and datatest 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(gdf_dataX, gdf_dataY, train_size=0.8)\n",
    "\n",
    "#information\n",
    "print(f'Original datasets: {gdf_dataX.shape[0], gdf_dataY.shape[0]} elements')\n",
    "print(f'Data X_train: {X_train.shape[0]} elements')\n",
    "print(f'Data X_test: {X_test.shape[0]} elements')\n",
    "print(f'Data y_train: {y_train.shape[0]} elements')\n",
    "print(f'Data y_test: {y_test.shape[0]} elements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work processing cuml with RAPIDS\n",
    "\n",
    "#Fase Preprocessing\n",
    "\n",
    "#Converting a categorical implementation to a numerical one\n",
    "from cuml.preprocessing.LabelEncoder import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "#select two columns potenciales for work train for xTrain\n",
    "value_usernameX = le.fit_transform(X_train.username)\n",
    "value_ipX = le.fit_transform(X_train.ip)\n",
    "\n",
    "#select two columns potenciales for work train for xTest\n",
    "value_usernameXT = le.fit_transform(X_test.username)\n",
    "value_ipXT = le.fit_transform(X_test.ip)\n",
    "\n",
    "#select two columns potenciales for work train for yTrain\n",
    "value_usernameY = le.fit_transform(y_train.username)\n",
    "value_ipY = le.fit_transform(y_train.ip)\n",
    "\n",
    "#select two columns potenciales for work train for yTest\n",
    "value_usernameYT = le.fit_transform(y_test.username)\n",
    "value_ipYT = le.fit_transform(y_test.ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algortih LinearRegression\n",
    "import cupy as cp\n",
    "from cuml.preprocessing import LabelBinarizer\n",
    "from cuml import LinearRegression\n",
    "from cuml.linear_model import LinearRegression\n",
    "\n",
    "#Value train-test eje Xtrain of column username\n",
    "dataTest = cudf.DataFrame()\n",
    "dataTest['usernameValueXtrain'] = cp.asarray(value_usernameX, dtype=cp.float32)\n",
    "dataTest['ipValueXtrain'] = cp.asarray(value_ipX, dtype=cp.float32)\n",
    "\n",
    "#Value train-test eje Ytrain of column username\n",
    "new_value = cp.asarray(value_usernameY, dtype=cp.float32)\n",
    "dataY = cudf.Series(new_value)\n",
    "\n",
    "#use algorith LinearRegresssion\n",
    "lr = LinearRegression(fit_intercept = True, normalize = False,\n",
    "                      algorithm = \"eig\")\n",
    "\n",
    "reg = lr.fit(dataTest, dataY)\n",
    "\n",
    "print(\"Coefficients:\")\n",
    "print(reg.coef_)\n",
    "\n",
    "print(\"Intercept:\")\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algortih RandonForest\n",
    "from cuml.ensemble import RandomForestClassifier as cuRFC\n",
    "\n",
    "dataTrainUSER = cp.asarray(value_usernameX, dtype=cp.float32)\n",
    "dataTestUSER = cp.asarray(value_usernameY, dtype=cp.int32)\n",
    "\n",
    "cuml_modelRDF = cuRFC(max_features=1.0,\n",
    "                   n_bins=2,\n",
    "                   n_estimators=2)\n",
    "\n",
    "cuml_modelRDF.fit(dataTrainUSER, dataTestUSER)\n",
    "cuml_predict = cuml_modelRDF.predict(dataTrainUSER)\n",
    "\n",
    "print(\"Predicted labels : \", cuml_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir columna course_user_tags\n",
    "#newcontext.columns = ['course_user_tags','user_id','org_id']\n",
    "#newcontext.head(2)\n",
    "\n",
    "#dfnewcontext = newcontext[\"course_user_tags\"].str.split(':', expand=True)\n",
    "#dfnewcontext.sort_values(0)\n",
    "#dfnewcontext.drop_duplicates(1, keep=\"last\", inplace=True)\n",
    "#dfnewcontext.drop(0, inplace=True)\n",
    "#dfnewcontext.columns = ['user_id']\n",
    "#indexNames = dfnewcontext[dfnewcontext['user_id'] == '{}' ].index\n",
    "#nuevodf = dfnewcontext.drop(indexNames, inplace=True)\n",
    "#nuevodf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
