{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "from pandas.io.json import json_normalize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########Carga con Pandas###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#exportación y lectura con pandas\n",
    "inicio = time.time()\n",
    "\n",
    "pd_Pandas = pd.read_csv('../../../Escritorio/df_data.csv',\n",
    "                        names='uno')\n",
    "fin = time.time()\n",
    "\n",
    "calcultedPD = fin-inicio\n",
    "print(\"Cálculo de extracción y lectura con Pandas = {}\".format(calcultedPD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########Transformación con Pandas################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertir en lista y despues en json\n",
    "import time\n",
    "startSecuenciaCPU = time.time()\n",
    "data = list(pd_Pandas['u'])\n",
    "da = []\n",
    "for i in range(0,len(data)):\n",
    "    d = data[i].split('.gz:')\n",
    "    da.append(json.loads((d[1])))\n",
    "    \n",
    "#DataFrame PANDAS\n",
    "new_data = pd.DataFrame(da)\n",
    "\n",
    "#solo conservo los datos de la columna username\n",
    "#mayor a 0\n",
    "snNull = new_data[new_data.username.map(len) > 0]\n",
    "\n",
    "#eliminar username dicc y opencampus\n",
    "snDicc = snNull[snNull.username != 'dicc']\n",
    "snCampus = snDicc[snDicc.username != 'opencampus']\n",
    "\n",
    "#eliminar filas con los datos perdidos\n",
    "snCampus.dropna(axis=0, how='any')\n",
    "\n",
    "#Eliminar columnas innecesarias no tiene relevancia\n",
    "snCampus.drop(['accept_language'],axis=1, inplace=True)\n",
    "snCampus.drop(['name'], axis=1, inplace=True)\n",
    "snCampus.drop(['agent'], axis=1, inplace=True)\n",
    "snCampus.drop(['page'], axis=1, inplace=True)\n",
    "snCampus.drop(['session'], axis=1, inplace=True)\n",
    "snCampus.drop(['event'], axis=1, inplace=True)\n",
    "snCampus.drop(['event_type'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#eliminar filas con datos perdidos\n",
    "snCampus.dropna(axis=0, how='any')\n",
    "\n",
    "\n",
    "\n",
    "dataLimpia = snCampus\n",
    "\n",
    "#Dividir toda la columna context\n",
    "contextData = dataLimpia['context'].values.tolist()\n",
    "new_contextData = pd.DataFrame(contextData, columns= ['course_user_tags',\n",
    "                                                      'course_id', 'path',\n",
    "                                                      'org_id', 'user_id'])\n",
    "generalData = pd.merge(dataLimpia.reset_index(),\n",
    "                       new_contextData.reset_index(),\n",
    "                       left_index=True, right_index=True)\n",
    "generalData = generalData.drop(['context','index_y', 'course_user_tags',\n",
    "                               'course_id','path'], axis=1)\n",
    "\n",
    "#eliminar filas con datos perdidos\n",
    "generalData.dropna(axis=0, how='any')\n",
    "\n",
    "#soltar duplicados\n",
    "snCampus.sort_values(\"username\") \n",
    "snCampus.drop_duplicates(subset='username',\n",
    "                         keep=False, inplace=False)\n",
    "\n",
    "\n",
    "#dividir columna time\n",
    "df_picru = pd.DataFrame(generalData['time'])\n",
    "datenew = df_picru.apply(lambda x: pd.to_datetime(x,errors = 'coerce', format = '%Y-%m-%d'))\n",
    "\n",
    "datenew['Day'] = datenew['time'].dt.day\n",
    "datenew['Month'] = datenew['time'].dt.month\n",
    "datenew['Year'] = datenew['time'].dt.year\n",
    "datenew['Hour'] = datenew['time'].dt.time\n",
    "\n",
    "datenew = datenew.drop(['time'], axis=1)\n",
    "datenew = datenew.drop(['Hour'], axis=1)\n",
    "\n",
    "#Unir todo el dataframe time al general\n",
    "generalData = pd.merge(generalData.reset_index(),\n",
    "                       datenew.reset_index(),\n",
    "                       left_index=True, right_index=True)\n",
    "generalData = generalData.drop(['time', 'index_x', 'index_y'], axis=1)\n",
    "\n",
    "#eliminar filas con datos perdidos\n",
    "generalData.dropna(axis=0, how='any')\n",
    "\n",
    "#resetear index\n",
    "generalData = generalData.reset_index()\n",
    "generalData = generalData.drop(['index'], axis=1)\n",
    "\n",
    "endSecuenciaCPU = time.time()\n",
    "cpuPandas = endSecuenciaCPU - startSecuenciaCPU\n",
    "\n",
    "print('Cálculo de transformación cpu-Pandas:', cpuPandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Información de toda la data con Pandas\n",
    "print('Nomnres de las columnas:',generalData.columns)\n",
    "print('Dimension del DataFrame:',generalData.shape)\n",
    "print('Tipos de datos de cada columna', generalData.dtypes)\n",
    "print('Información DATA general con Pandas:')\n",
    "generalData.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######Carga con Pandas############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar la data entendible en un nuevo csv\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "da_data = 'data_mejoraPandas.csv'\n",
    "generalData.to_csv(da_data)\n",
    "\n",
    "end = time.time()\n",
    "calculated = end - start\n",
    "\n",
    "print(\"Cálculo de carga cpu-Pandas = {}\".format(calculated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nueva_data = pd.read_csv('data_mejoraPandas.csv')#los datos de las 100000\n",
    "nueva_data = nueva_data.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "print('Tipos de datos de cada columna', nueva_data.dtypes)\n",
    "print('Información Data')\n",
    "nueva_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Proceso Machine learning########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Original: (196867, 196867) elementos\n",
      "Data X_train: 157493 elementos\n",
      "Data X_test: 39374 elementos\n",
      "Data y_train: 157493 elementos\n",
      "Data y_test: 39374 elementos\n",
      "\n",
      "Cálculo fase dividir dataset con sklearn cpu-sklearn = 0.05218243598937988\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "inicio_Split = time.time()\n",
    "\n",
    "#Fase1 de Dividir dataset con sklearn\n",
    "#Asignar dataset general a nuevas variables\n",
    "pd_dataX = nueva_data\n",
    "pd_dataY = nueva_data\n",
    "\n",
    "#Dividir datasets en train y test\n",
    "#datatrain 80% y datatest 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(pd_dataX, pd_dataY, train_size=0.8)\n",
    "\n",
    "#información\n",
    "print(f'Dataset Original: {pd_dataX.shape[0], pd_dataY.shape[0]} elementos')\n",
    "print(f'Data X_train: {X_train.shape[0]} elementos')\n",
    "print(f'Data X_test: {X_test.shape[0]} elementos')\n",
    "print(f'Data y_train: {y_train.shape[0]} elementos')\n",
    "print(f'Data y_test: {y_test.shape[0]} elementos')\n",
    "print('')\n",
    "\n",
    "fin_Split = time.time()\n",
    "calculo_Split_ML = fin_Split - inicio_Split\n",
    "\n",
    "print(\"Cálculo fase dividir dataset con sklearn cpu-sklearn = {}\".format(calculo_Split_ML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn import preprocessing\n",
    "\n",
    "inicio_Pre = time.time()\n",
    "\n",
    "#Fase Preprocesamiento con sklearn\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "#seleccionar columnas potenciales para work train de xTrain\n",
    "value_usernameX = le.fit_transform(X_train.username)\n",
    "value_EventSourceX = le.fit_transform(X_train.event_source)\n",
    "value_DayX = le.fit_transform(X_train.Day)\n",
    "\n",
    "#seleccionar columnas potenciales para work train de xTest\n",
    "value_usernameXT = le.fit_transform(X_test.username)\n",
    "value_EventSourceXT = le.fit_transform(X_test.event_source)\n",
    "value_DayXT = le.fit_transform(X_test.Day)\n",
    "\n",
    "#seleccionar columnas potenciales para work train de yTrain\n",
    "value_usernameY = le.fit_transform(y_train.username)\n",
    "value_EventSourceY = le.fit_transform(y_train.event_source)\n",
    "value_DayY = le.fit_transform(y_train.Day)\n",
    "\n",
    "#seleccionar columnas potenciales para work train de yTest\n",
    "value_usernameYT = le.fit_transform(y_test.username)\n",
    "value_EventSourceYT = le.fit_transform(y_test.event_source)\n",
    "value_DayYT = le.fit_transform(y_test.Day)\n",
    "\n",
    "fin_Pre = time.time()\n",
    "calculo_Pre_ML = fin_Pre - inicio_Pre\n",
    "\n",
    "print(\"Cálculo fase preprocesamiento con sklearn = {}\".format(calculo_Pre_ML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Fase Uso de Algoritmo ML con sklearn :Algoritmo LinearRegression\n",
    "\n",
    "inicio_ML = time.time()\n",
    "\n",
    "#Creación de un nuevo dataframe Train\n",
    "dataTrain = pd.DataFrame()\n",
    "dataTrain['username'] = np.array(value_usernameX, dtype=np.float32)\n",
    "dataTrain['day'] = np.array(value_DayX, dtype=np.float32)\n",
    "\n",
    "#Creación de un nuevo dataframe Test\n",
    "new_value = np.array(value_usernameY, dtype=np.float32)\n",
    "dataY = pd.Series(new_value)\n",
    "\n",
    "lr_reg = LinearRegression(fit_intercept= True, normalize = False)\n",
    "reg = lr_reg.fit(dataTrain, dataY)\n",
    "\n",
    "fin_ML = time.time()\n",
    "calculo_Algorit_ML = fin_ML - inicio_ML\n",
    "\n",
    "print(\"Algoritmo Regresión Lineal\")\n",
    "print(\"Coeficientes:\")\n",
    "print(reg.coef_)\n",
    "print(\"Intercepción:\")\n",
    "print(reg.intercept_)\n",
    "print('Predicción del modelo:')\n",
    "print(lr_reg.predict(dataTrain))\n",
    "print('')\n",
    "\n",
    "print(\"Cálculo fase de entrenamiento algoritmo Machine Learning con sklearn = {}\".format(calculo_Algorit_ML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algoritmo Regresión Logística de sklearn\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "inicio_RL = time.time()\n",
    "\n",
    "#Creación de un nuevo dataframe Train \n",
    "dataTrain = pd.DataFrame()\n",
    "dataTrain['username'] = np.array(value_usernameX, dtype=np.float32)\n",
    "dataTrain['day'] = np.asarray(value_DayX, dtype=np.float32)\n",
    "\n",
    "#Creación de un nuevo dataframe Test\n",
    "new_value = np.array(value_usernameY, dtype=np.float32)\n",
    "dataTest = pd.Series(new_value)\n",
    "\n",
    "reg = LogisticRegression(fit_intercept = True,\n",
    "                         max_iter = 100)\n",
    "reg.fit(dataTrain, dataTest)\n",
    "\n",
    "fin_RL = time.time()\n",
    "calculo_RL = fin_RL - inicio_RL\n",
    "\n",
    "print(\"Coefficients:\")\n",
    "print(reg.coef_)\n",
    "print(\"Intercept:\")\n",
    "print(reg.intercept_)\n",
    "print('Predicción del modelo:')\n",
    "print(reg.predict(dataTrain))\n",
    "print('')\n",
    "\n",
    "print(\"Cálculo del algoritmo Regresión Logistica con sklearn = {}\".format(calculo_RL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######Visualización########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inicio_grafico = time.time()\n",
    "\n",
    "dataTrain.plot(kind='bar', x='day',y='username', title='Gráfico de Barras',  width=0.5)\n",
    "\n",
    "fin_grafico = time.time()\n",
    "\n",
    "calculo_grafico = fin_grafico - inicio_grafico\n",
    "print(\"Cálculo del proceso de Visualización con matplotlib cpu-matplotlib = {}\".format(calculo_grafico))\n",
    "\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear gráfico de líneas estadíssticas\n",
    "grafico_lin = dataTrain.plot(kind='line', x='day',y='username', title='Gráfico de Lineas Estadísticas',  width=0.5)\n",
    "\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detalles del proceso con otras herramientas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algoritmo Random Forest de sklearn\n",
    "\"\"\"import time\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "inicioRF = time.time()\n",
    "\n",
    "dataTrainUSER = np.array(value_usernameX, dtype=np.float32)\n",
    "dataTestUSER = np.array(value_usernameY, dtype=np.int32)\n",
    "\n",
    "dataTrainUSER, dataTestUSER = make_classification(n_samples=10, n_features=4,\n",
    "                                                 n_informative=2, n_redundant=0,\n",
    "                                                 random_state=0)\n",
    "\n",
    "sk_modelRDF = RandomForestClassifier(max_features=1.0,\n",
    "                             min_samples_split = 2,\n",
    "                             n_estimators=2)\n",
    "\n",
    "sk_modelRDF.fit(dataTrainUSER, dataTestUSER)\n",
    "sk_predict = sk_modelRDF.predict(dataTrainUSER)\n",
    "\n",
    "finRF = time.time()\n",
    "calculoRF = finRF - inicioRF\n",
    "\n",
    "print('Predict labels:', sk_predict)\n",
    "print('')\n",
    "\n",
    "print(\"Cálculo fase de entrenamiento algoritmo Random Forest con sklearn = {}\".format(calculoRF))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
